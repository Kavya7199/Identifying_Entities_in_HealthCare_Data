{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Identifying Entities in Healthcare Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### There are eight major tasks that we need to perform. They are as follows:\n",
    "\n",
    "- Data preprocessing\n",
    "- Concept identification\n",
    "- Defining the features for CRF\n",
    "- Getting the features words and sentences\n",
    "- Defining input and target variables\n",
    "- Building the model\n",
    "- Evaluating the model\n",
    "- Identifying the diseases and predicted treatment using a custom NER"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing\n",
    "The dataset is in the token format instead of sentences, we need to construct the sentences from the words. There are blank lines after the completion of each sentence or a set of labels in label files and we need to build a logic to arrange them into sentences or a sequence of labels in the case of label files.\n",
    "\n",
    "### We need to do the following three tasks after processing and modifying the datasets:\n",
    "\n",
    "- Construct proper sentences from individual words and print five sentences along with their labels.\n",
    "- Print the correct count of the number of sentences in the processed train and test dataset.\n",
    "- Correctly count the number of lines of labels in the processed train and test dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the required libraries\n",
    "\n",
    "import spacy\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn_crfsuite\n",
    "from sklearn_crfsuite import metrics\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the en_core_web_sm\n",
    "nlp_model = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the required files\n",
    "tr_sent = open('train_sent', 'r')\n",
    "tr_label = open('train_label', 'r')\n",
    "te_sent = open('test_sent', 'r')\n",
    "te_label = open('test_label', 'r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write a function which forms the tokens in to sentences and values in to labels\n",
    "\n",
    "def process_datatxt_file(filename):\n",
    "  input_file = open(filename, 'r')\n",
    "  file_content = input_file.readlines() \n",
    "  input_file.close()\n",
    "\n",
    "  # To store list of sequences (sentences or labels)\n",
    "  out_lines = [] \n",
    "\n",
    "  line_content = \"\"\n",
    "\n",
    "  for word in file_content:\n",
    "    word = word.strip() \n",
    "    # If empty line, add the current sequence to out_lines\n",
    "    if word == \"\": \n",
    "      out_lines.append(line_content)\n",
    "      line_content = \"\"; # re-initialize, new line starts\n",
    "    else:\n",
    "      if line_content: # if non-empty, add new word after space, part of current sentence\n",
    "        line_content += \" \"+word\n",
    "      else:\n",
    "        line_content = word # first word, no space required\n",
    "\n",
    "  return out_lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare train sentences and labels \n",
    "train_sentences = process_datatxt_file('train_sent')\n",
    "train_labels = process_datatxt_file('train_label')\n",
    "\n",
    "# Prepare test sentences and labels\n",
    "test_sentences = process_datatxt_file('test_sent')\n",
    "test_labels = process_datatxt_file('test_label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence: All live births > or = 23 weeks at the University of Vermont in 1995 ( n = 2395 ) were retrospectively analyzed for delivery route , indication for cesarean , gestational age , parity , and practice group ( to reflect risk status )\n",
      "Labels: O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O \n",
      "\n",
      "\n",
      "Sentence: The total cesarean rate was 14.4 % ( 344 of 2395 ) , and the primary rate was 11.4 % ( 244 of 2144 )\n",
      "Labels: O O O O O O O O O O O O O O O O O O O O O O O O O \n",
      "\n",
      "\n",
      "Sentence: Abnormal presentation was the most common indication ( 25.6 % , 88 of 344 )\n",
      "Labels: O O O O O O O O O O O O O O O \n",
      "\n",
      "\n",
      "Sentence: The `` corrected '' cesarean rate ( maternal-fetal medicine and transported patients excluded ) was 12.4 % ( 273 of 2194 ) , and the `` corrected '' primary rate was 9.6 % ( 190 of 1975 )\n",
      "Labels: O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O \n",
      "\n",
      "\n",
      "Sentence: Arrest of dilation was the most common indication in both `` corrected '' subgroups ( 23.4 and 24.6 % , respectively )\n",
      "Labels: O O O O O O O O O O O O O O O O O O O O O O \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Print the 5 sentences from the processed dataset\n",
    "for i in range(5):\n",
    "  print(\"Sentence:\", train_sentences[i])\n",
    "  print(\"Labels:\", train_labels[i], \"\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No. of lines in train_sentences: 2599\n",
      "No. of lines in test_sentences: 1056\n"
     ]
    }
   ],
   "source": [
    "# Count the number of sentences in the processed train and test dataset\n",
    "print(\"Number of lines in train_sentences:\", len(train_sentences))\n",
    "print(\"Number of lines in test_sentences:\", len(test_sentences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No. of lines in train_labels: 2599\n",
      "No. of lines in test_labels: 1056\n"
     ]
    }
   ],
   "source": [
    "# Count the number of lines of labels in the processed train and test dataset. \n",
    "print(\"Number of lines in train_labels:\", len(train_labels))\n",
    "print(\"Number of lines in test_labels:\", len(test_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Concept Identification\n",
    "After preprocessing, we will first explore what are the various concepts present in the dataset. For this task, we will use PoS tagging. It is good to identify all the words from the corpus that have a tag of NOUN or PROPN (nouns) and prepare a dictionary of their counts. We will then output the top 25 most frequently discussed concepts in the entire corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract those tokens which have NOUN or PROPN as their PoS tag and find their frequency\n",
    "detectCustomPOSTags = {}\n",
    "for sentences in (train_sentences, test_sentences):\n",
    "  for sentence in sentences:\n",
    "    processed_sentence = nlp_model(sentence) # Process each sentence by spacy model\n",
    "    for token in processed_sentence:\n",
    "      if(token.pos_ == 'NOUN' or token.pos_ == 'PROPN'): # Check if the token is a noun or proper noun\n",
    "        detectCustomPOSTags[token.text] = detectCustomPOSTags.get(token.text, 0) + 1; #increase its frequency if it is noun\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('patients', 492),\n",
       " ('treatment', 281),\n",
       " ('%', 247),\n",
       " ('cancer', 200),\n",
       " ('therapy', 175),\n",
       " ('study', 154),\n",
       " ('disease', 142),\n",
       " ('cell', 140),\n",
       " ('lung', 116),\n",
       " ('group', 94),\n",
       " ('gene', 88),\n",
       " ('chemotherapy', 88),\n",
       " ('effects', 85),\n",
       " ('results', 78),\n",
       " ('women', 77),\n",
       " ('use', 75),\n",
       " ('risk', 71),\n",
       " ('cases', 71),\n",
       " ('surgery', 71),\n",
       " ('analysis', 70),\n",
       " ('rate', 67),\n",
       " ('response', 66),\n",
       " ('survival', 65),\n",
       " ('children', 64),\n",
       " ('effect', 63)]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print the top 25 most common tokens with NOUN or PROPN PoS tags\n",
    "cnpt_counter = Counter(detectCustomPOSTags)\n",
    "cnpt_counter.most_common(25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining features for CRF\n",
    "- Define the features with the PoS tag as one of the features.\n",
    "- While defining the features in which you have used the PoS tags, you also need to consider the preceding word of the current word. The use of the information of the preceding word makes the CRF model more accurate and exhaustive.\n",
    "- Mark the beginning and the end words of a sentence correctly in the form of features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's define the features to get the feature value for one word.\n",
    "def getFeaturesForOneWord(sentence, pos, pos_tags):\n",
    "  word = sentence[pos]\n",
    "\n",
    "  # Define 12 features with PoS tag as one of the features\n",
    "  features = [\n",
    "    'word.lower=' + word.lower(), # serves as word id\n",
    "    'word[-3:]=' + word[-3:],     # last three characters\n",
    "    'word[0:]=' + word[0:],     # first character\n",
    "    'word[-1:]=' + word[-1:],     # last character\n",
    "    'word[-2:]=' + word[-2:],     # last two characters\n",
    "    'word.isupper=%s' % word.isupper(),  # is the word in all uppercase\n",
    "    'word.isdigit=%s' % word.isdigit(),  # is the word a number\n",
    "    'word.startsWithCapital=%s' % word[0].isupper(), # is the word starting with a capital letter\n",
    "    'word.pos=' + pos_tags[pos]\n",
    "  ]\n",
    "\n",
    "  # Use the previous word also while defining features\n",
    "  if(pos > 0):\n",
    "    prev_word = sentence[pos-1]\n",
    "    features.extend([\n",
    "    'prev_word.lower=' + prev_word.lower(), \n",
    "    'prev_word.isupper=%s' % prev_word.isupper(),\n",
    "    'prev_word.isdigit=%s' % prev_word.isdigit(),\n",
    "    'prev_word.startsWithCapital=%s' % prev_word[0].isupper(),\n",
    "    'prev_word.pos=' + pos_tags[pos-1]\n",
    "   \n",
    "  ])\n",
    "    \n",
    "  # Mark the begining and the end words of a sentence correctly in the form of features.\n",
    "  else:\n",
    "    features.append('BEG') # feature to track begin of sentence \n",
    "\n",
    "  if(pos == len(sentence)-1):\n",
    "    features.append('END') # feature to track end of sentence\n",
    "  return features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting the features and the labels of sentences:\n",
    "- Write the code to get the features value of a sentence after defining the features in the previous step.\n",
    "- Write the code to get a list of labels of a given preprocessed label line that you have created earlier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write a code to get features for a sentence.\n",
    "# Define a function to get features for a sentence using the 'getFeaturesForOneWord' function.\n",
    "def getFeaturesForOneSentence(sentence):\n",
    "  pos_processed_sentence = nlp_model(sentence) #spacy is applied to sentence\n",
    "  pos_tags = [] #correctly identify pos tags\n",
    "  for token in pos_processed_sentence:\n",
    "    pos_tags.append(token.pos_)\n",
    "\n",
    "  sentence_list = sentence.split() # List of words in sentence\n",
    "  \n",
    "  # Correctly calling getFeaturesForOneWord defined above\n",
    "  return [getFeaturesForOneWord(sentence_list, pos, pos_tags) for pos in range(len(sentence_list))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write a code to get the labels for a sentence.\n",
    "# Define a function to get the labels for a sentence.\n",
    "def getLabelsInListForOneSentence(labels):\n",
    "  return labels.split()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining input and target variables\n",
    "- Extract the features values for each sentence as an input variable for the CRF model in the test and the train dataset.\n",
    "- Extract the labels as the target variable for the test and the train dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the features values for each sentence as input variable  for CRF model in test and the train dataset \n",
    "X_train = [getFeaturesForOneSentence(sentence) for sentence in train_sentences]\n",
    "X_test = [getFeaturesForOneSentence(sentence) for sentence in test_sentences]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['word.lower=all', 'word[-3:]=All', 'word[0:]=All', 'word[-1:]=l', 'word[-2:]=ll', 'word.isupper=False', 'word.isdigit=False', 'word.startsWithCapital=True', 'word.pos=DET', 'BEG'], ['word.lower=live', 'word[-3:]=ive', 'word[0:]=live', 'word[-1:]=e', 'word[-2:]=ve', 'word.isupper=False', 'word.isdigit=False', 'word.startsWithCapital=False', 'word.pos=ADJ', 'prev_word.lower=all', 'prev_word.isupper=False', 'prev_word.isdigit=False', 'prev_word.startsWithCapital=True', 'prev_word.pos=DET'], ['word.lower=births', 'word[-3:]=ths', 'word[0:]=births', 'word[-1:]=s', 'word[-2:]=hs', 'word.isupper=False', 'word.isdigit=False', 'word.startsWithCapital=False', 'word.pos=NOUN', 'prev_word.lower=live', 'prev_word.isupper=False', 'prev_word.isdigit=False', 'prev_word.startsWithCapital=False', 'prev_word.pos=ADJ'], ['word.lower=>', 'word[-3:]=>', 'word[0:]=>', 'word[-1:]=>', 'word[-2:]=>', 'word.isupper=False', 'word.isdigit=False', 'word.startsWithCapital=False', 'word.pos=PUNCT', 'prev_word.lower=births', 'prev_word.isupper=False', 'prev_word.isdigit=False', 'prev_word.startsWithCapital=False', 'prev_word.pos=NOUN'], ['word.lower=or', 'word[-3:]=or', 'word[0:]=or', 'word[-1:]=r', 'word[-2:]=or', 'word.isupper=False', 'word.isdigit=False', 'word.startsWithCapital=False', 'word.pos=CCONJ', 'prev_word.lower=>', 'prev_word.isupper=False', 'prev_word.isdigit=False', 'prev_word.startsWithCapital=False', 'prev_word.pos=PUNCT'], ['word.lower==', 'word[-3:]==', 'word[0:]==', 'word[-1:]==', 'word[-2:]==', 'word.isupper=False', 'word.isdigit=False', 'word.startsWithCapital=False', 'word.pos=SYM', 'prev_word.lower=or', 'prev_word.isupper=False', 'prev_word.isdigit=False', 'prev_word.startsWithCapital=False', 'prev_word.pos=CCONJ'], ['word.lower=23', 'word[-3:]=23', 'word[0:]=23', 'word[-1:]=3', 'word[-2:]=23', 'word.isupper=False', 'word.isdigit=True', 'word.startsWithCapital=False', 'word.pos=NUM', 'prev_word.lower==', 'prev_word.isupper=False', 'prev_word.isdigit=False', 'prev_word.startsWithCapital=False', 'prev_word.pos=SYM'], ['word.lower=weeks', 'word[-3:]=eks', 'word[0:]=weeks', 'word[-1:]=s', 'word[-2:]=ks', 'word.isupper=False', 'word.isdigit=False', 'word.startsWithCapital=False', 'word.pos=NOUN', 'prev_word.lower=23', 'prev_word.isupper=False', 'prev_word.isdigit=True', 'prev_word.startsWithCapital=False', 'prev_word.pos=NUM'], ['word.lower=at', 'word[-3:]=at', 'word[0:]=at', 'word[-1:]=t', 'word[-2:]=at', 'word.isupper=False', 'word.isdigit=False', 'word.startsWithCapital=False', 'word.pos=ADP', 'prev_word.lower=weeks', 'prev_word.isupper=False', 'prev_word.isdigit=False', 'prev_word.startsWithCapital=False', 'prev_word.pos=NOUN'], ['word.lower=the', 'word[-3:]=the', 'word[0:]=the', 'word[-1:]=e', 'word[-2:]=he', 'word.isupper=False', 'word.isdigit=False', 'word.startsWithCapital=False', 'word.pos=DET', 'prev_word.lower=at', 'prev_word.isupper=False', 'prev_word.isdigit=False', 'prev_word.startsWithCapital=False', 'prev_word.pos=ADP'], ['word.lower=university', 'word[-3:]=ity', 'word[0:]=University', 'word[-1:]=y', 'word[-2:]=ty', 'word.isupper=False', 'word.isdigit=False', 'word.startsWithCapital=True', 'word.pos=PROPN', 'prev_word.lower=the', 'prev_word.isupper=False', 'prev_word.isdigit=False', 'prev_word.startsWithCapital=False', 'prev_word.pos=DET'], ['word.lower=of', 'word[-3:]=of', 'word[0:]=of', 'word[-1:]=f', 'word[-2:]=of', 'word.isupper=False', 'word.isdigit=False', 'word.startsWithCapital=False', 'word.pos=ADP', 'prev_word.lower=university', 'prev_word.isupper=False', 'prev_word.isdigit=False', 'prev_word.startsWithCapital=True', 'prev_word.pos=PROPN'], ['word.lower=vermont', 'word[-3:]=ont', 'word[0:]=Vermont', 'word[-1:]=t', 'word[-2:]=nt', 'word.isupper=False', 'word.isdigit=False', 'word.startsWithCapital=True', 'word.pos=PROPN', 'prev_word.lower=of', 'prev_word.isupper=False', 'prev_word.isdigit=False', 'prev_word.startsWithCapital=False', 'prev_word.pos=ADP'], ['word.lower=in', 'word[-3:]=in', 'word[0:]=in', 'word[-1:]=n', 'word[-2:]=in', 'word.isupper=False', 'word.isdigit=False', 'word.startsWithCapital=False', 'word.pos=ADP', 'prev_word.lower=vermont', 'prev_word.isupper=False', 'prev_word.isdigit=False', 'prev_word.startsWithCapital=True', 'prev_word.pos=PROPN'], ['word.lower=1995', 'word[-3:]=995', 'word[0:]=1995', 'word[-1:]=5', 'word[-2:]=95', 'word.isupper=False', 'word.isdigit=True', 'word.startsWithCapital=False', 'word.pos=NUM', 'prev_word.lower=in', 'prev_word.isupper=False', 'prev_word.isdigit=False', 'prev_word.startsWithCapital=False', 'prev_word.pos=ADP'], ['word.lower=(', 'word[-3:]=(', 'word[0:]=(', 'word[-1:]=(', 'word[-2:]=(', 'word.isupper=False', 'word.isdigit=False', 'word.startsWithCapital=False', 'word.pos=PUNCT', 'prev_word.lower=1995', 'prev_word.isupper=False', 'prev_word.isdigit=True', 'prev_word.startsWithCapital=False', 'prev_word.pos=NUM'], ['word.lower=n', 'word[-3:]=n', 'word[0:]=n', 'word[-1:]=n', 'word[-2:]=n', 'word.isupper=False', 'word.isdigit=False', 'word.startsWithCapital=False', 'word.pos=CCONJ', 'prev_word.lower=(', 'prev_word.isupper=False', 'prev_word.isdigit=False', 'prev_word.startsWithCapital=False', 'prev_word.pos=PUNCT'], ['word.lower==', 'word[-3:]==', 'word[0:]==', 'word[-1:]==', 'word[-2:]==', 'word.isupper=False', 'word.isdigit=False', 'word.startsWithCapital=False', 'word.pos=SYM', 'prev_word.lower=n', 'prev_word.isupper=False', 'prev_word.isdigit=False', 'prev_word.startsWithCapital=False', 'prev_word.pos=CCONJ'], ['word.lower=2395', 'word[-3:]=395', 'word[0:]=2395', 'word[-1:]=5', 'word[-2:]=95', 'word.isupper=False', 'word.isdigit=True', 'word.startsWithCapital=False', 'word.pos=NUM', 'prev_word.lower==', 'prev_word.isupper=False', 'prev_word.isdigit=False', 'prev_word.startsWithCapital=False', 'prev_word.pos=SYM'], ['word.lower=)', 'word[-3:]=)', 'word[0:]=)', 'word[-1:]=)', 'word[-2:]=)', 'word.isupper=False', 'word.isdigit=False', 'word.startsWithCapital=False', 'word.pos=PUNCT', 'prev_word.lower=2395', 'prev_word.isupper=False', 'prev_word.isdigit=True', 'prev_word.startsWithCapital=False', 'prev_word.pos=NUM'], ['word.lower=were', 'word[-3:]=ere', 'word[0:]=were', 'word[-1:]=e', 'word[-2:]=re', 'word.isupper=False', 'word.isdigit=False', 'word.startsWithCapital=False', 'word.pos=AUX', 'prev_word.lower=)', 'prev_word.isupper=False', 'prev_word.isdigit=False', 'prev_word.startsWithCapital=False', 'prev_word.pos=PUNCT'], ['word.lower=retrospectively', 'word[-3:]=ely', 'word[0:]=retrospectively', 'word[-1:]=y', 'word[-2:]=ly', 'word.isupper=False', 'word.isdigit=False', 'word.startsWithCapital=False', 'word.pos=ADV', 'prev_word.lower=were', 'prev_word.isupper=False', 'prev_word.isdigit=False', 'prev_word.startsWithCapital=False', 'prev_word.pos=AUX'], ['word.lower=analyzed', 'word[-3:]=zed', 'word[0:]=analyzed', 'word[-1:]=d', 'word[-2:]=ed', 'word.isupper=False', 'word.isdigit=False', 'word.startsWithCapital=False', 'word.pos=VERB', 'prev_word.lower=retrospectively', 'prev_word.isupper=False', 'prev_word.isdigit=False', 'prev_word.startsWithCapital=False', 'prev_word.pos=ADV'], ['word.lower=for', 'word[-3:]=for', 'word[0:]=for', 'word[-1:]=r', 'word[-2:]=or', 'word.isupper=False', 'word.isdigit=False', 'word.startsWithCapital=False', 'word.pos=ADP', 'prev_word.lower=analyzed', 'prev_word.isupper=False', 'prev_word.isdigit=False', 'prev_word.startsWithCapital=False', 'prev_word.pos=VERB'], ['word.lower=delivery', 'word[-3:]=ery', 'word[0:]=delivery', 'word[-1:]=y', 'word[-2:]=ry', 'word.isupper=False', 'word.isdigit=False', 'word.startsWithCapital=False', 'word.pos=NOUN', 'prev_word.lower=for', 'prev_word.isupper=False', 'prev_word.isdigit=False', 'prev_word.startsWithCapital=False', 'prev_word.pos=ADP'], ['word.lower=route', 'word[-3:]=ute', 'word[0:]=route', 'word[-1:]=e', 'word[-2:]=te', 'word.isupper=False', 'word.isdigit=False', 'word.startsWithCapital=False', 'word.pos=NOUN', 'prev_word.lower=delivery', 'prev_word.isupper=False', 'prev_word.isdigit=False', 'prev_word.startsWithCapital=False', 'prev_word.pos=NOUN'], ['word.lower=,', 'word[-3:]=,', 'word[0:]=,', 'word[-1:]=,', 'word[-2:]=,', 'word.isupper=False', 'word.isdigit=False', 'word.startsWithCapital=False', 'word.pos=PUNCT', 'prev_word.lower=route', 'prev_word.isupper=False', 'prev_word.isdigit=False', 'prev_word.startsWithCapital=False', 'prev_word.pos=NOUN'], ['word.lower=indication', 'word[-3:]=ion', 'word[0:]=indication', 'word[-1:]=n', 'word[-2:]=on', 'word.isupper=False', 'word.isdigit=False', 'word.startsWithCapital=False', 'word.pos=NOUN', 'prev_word.lower=,', 'prev_word.isupper=False', 'prev_word.isdigit=False', 'prev_word.startsWithCapital=False', 'prev_word.pos=PUNCT'], ['word.lower=for', 'word[-3:]=for', 'word[0:]=for', 'word[-1:]=r', 'word[-2:]=or', 'word.isupper=False', 'word.isdigit=False', 'word.startsWithCapital=False', 'word.pos=ADP', 'prev_word.lower=indication', 'prev_word.isupper=False', 'prev_word.isdigit=False', 'prev_word.startsWithCapital=False', 'prev_word.pos=NOUN'], ['word.lower=cesarean', 'word[-3:]=ean', 'word[0:]=cesarean', 'word[-1:]=n', 'word[-2:]=an', 'word.isupper=False', 'word.isdigit=False', 'word.startsWithCapital=False', 'word.pos=ADJ', 'prev_word.lower=for', 'prev_word.isupper=False', 'prev_word.isdigit=False', 'prev_word.startsWithCapital=False', 'prev_word.pos=ADP'], ['word.lower=,', 'word[-3:]=,', 'word[0:]=,', 'word[-1:]=,', 'word[-2:]=,', 'word.isupper=False', 'word.isdigit=False', 'word.startsWithCapital=False', 'word.pos=PUNCT', 'prev_word.lower=cesarean', 'prev_word.isupper=False', 'prev_word.isdigit=False', 'prev_word.startsWithCapital=False', 'prev_word.pos=ADJ'], ['word.lower=gestational', 'word[-3:]=nal', 'word[0:]=gestational', 'word[-1:]=l', 'word[-2:]=al', 'word.isupper=False', 'word.isdigit=False', 'word.startsWithCapital=False', 'word.pos=ADJ', 'prev_word.lower=,', 'prev_word.isupper=False', 'prev_word.isdigit=False', 'prev_word.startsWithCapital=False', 'prev_word.pos=PUNCT'], ['word.lower=age', 'word[-3:]=age', 'word[0:]=age', 'word[-1:]=e', 'word[-2:]=ge', 'word.isupper=False', 'word.isdigit=False', 'word.startsWithCapital=False', 'word.pos=NOUN', 'prev_word.lower=gestational', 'prev_word.isupper=False', 'prev_word.isdigit=False', 'prev_word.startsWithCapital=False', 'prev_word.pos=ADJ'], ['word.lower=,', 'word[-3:]=,', 'word[0:]=,', 'word[-1:]=,', 'word[-2:]=,', 'word.isupper=False', 'word.isdigit=False', 'word.startsWithCapital=False', 'word.pos=PUNCT', 'prev_word.lower=age', 'prev_word.isupper=False', 'prev_word.isdigit=False', 'prev_word.startsWithCapital=False', 'prev_word.pos=NOUN'], ['word.lower=parity', 'word[-3:]=ity', 'word[0:]=parity', 'word[-1:]=y', 'word[-2:]=ty', 'word.isupper=False', 'word.isdigit=False', 'word.startsWithCapital=False', 'word.pos=NOUN', 'prev_word.lower=,', 'prev_word.isupper=False', 'prev_word.isdigit=False', 'prev_word.startsWithCapital=False', 'prev_word.pos=PUNCT'], ['word.lower=,', 'word[-3:]=,', 'word[0:]=,', 'word[-1:]=,', 'word[-2:]=,', 'word.isupper=False', 'word.isdigit=False', 'word.startsWithCapital=False', 'word.pos=PUNCT', 'prev_word.lower=parity', 'prev_word.isupper=False', 'prev_word.isdigit=False', 'prev_word.startsWithCapital=False', 'prev_word.pos=NOUN'], ['word.lower=and', 'word[-3:]=and', 'word[0:]=and', 'word[-1:]=d', 'word[-2:]=nd', 'word.isupper=False', 'word.isdigit=False', 'word.startsWithCapital=False', 'word.pos=CCONJ', 'prev_word.lower=,', 'prev_word.isupper=False', 'prev_word.isdigit=False', 'prev_word.startsWithCapital=False', 'prev_word.pos=PUNCT'], ['word.lower=practice', 'word[-3:]=ice', 'word[0:]=practice', 'word[-1:]=e', 'word[-2:]=ce', 'word.isupper=False', 'word.isdigit=False', 'word.startsWithCapital=False', 'word.pos=NOUN', 'prev_word.lower=and', 'prev_word.isupper=False', 'prev_word.isdigit=False', 'prev_word.startsWithCapital=False', 'prev_word.pos=CCONJ'], ['word.lower=group', 'word[-3:]=oup', 'word[0:]=group', 'word[-1:]=p', 'word[-2:]=up', 'word.isupper=False', 'word.isdigit=False', 'word.startsWithCapital=False', 'word.pos=NOUN', 'prev_word.lower=practice', 'prev_word.isupper=False', 'prev_word.isdigit=False', 'prev_word.startsWithCapital=False', 'prev_word.pos=NOUN'], ['word.lower=(', 'word[-3:]=(', 'word[0:]=(', 'word[-1:]=(', 'word[-2:]=(', 'word.isupper=False', 'word.isdigit=False', 'word.startsWithCapital=False', 'word.pos=PUNCT', 'prev_word.lower=group', 'prev_word.isupper=False', 'prev_word.isdigit=False', 'prev_word.startsWithCapital=False', 'prev_word.pos=NOUN'], ['word.lower=to', 'word[-3:]=to', 'word[0:]=to', 'word[-1:]=o', 'word[-2:]=to', 'word.isupper=False', 'word.isdigit=False', 'word.startsWithCapital=False', 'word.pos=PART', 'prev_word.lower=(', 'prev_word.isupper=False', 'prev_word.isdigit=False', 'prev_word.startsWithCapital=False', 'prev_word.pos=PUNCT'], ['word.lower=reflect', 'word[-3:]=ect', 'word[0:]=reflect', 'word[-1:]=t', 'word[-2:]=ct', 'word.isupper=False', 'word.isdigit=False', 'word.startsWithCapital=False', 'word.pos=VERB', 'prev_word.lower=to', 'prev_word.isupper=False', 'prev_word.isdigit=False', 'prev_word.startsWithCapital=False', 'prev_word.pos=PART'], ['word.lower=risk', 'word[-3:]=isk', 'word[0:]=risk', 'word[-1:]=k', 'word[-2:]=sk', 'word.isupper=False', 'word.isdigit=False', 'word.startsWithCapital=False', 'word.pos=NOUN', 'prev_word.lower=reflect', 'prev_word.isupper=False', 'prev_word.isdigit=False', 'prev_word.startsWithCapital=False', 'prev_word.pos=VERB'], ['word.lower=status', 'word[-3:]=tus', 'word[0:]=status', 'word[-1:]=s', 'word[-2:]=us', 'word.isupper=False', 'word.isdigit=False', 'word.startsWithCapital=False', 'word.pos=NOUN', 'prev_word.lower=risk', 'prev_word.isupper=False', 'prev_word.isdigit=False', 'prev_word.startsWithCapital=False', 'prev_word.pos=NOUN'], ['word.lower=)', 'word[-3:]=)', 'word[0:]=)', 'word[-1:]=)', 'word[-2:]=)', 'word.isupper=False', 'word.isdigit=False', 'word.startsWithCapital=False', 'word.pos=PUNCT', 'prev_word.lower=status', 'prev_word.isupper=False', 'prev_word.isdigit=False', 'prev_word.startsWithCapital=False', 'prev_word.pos=NOUN', 'END']]\n"
     ]
    }
   ],
   "source": [
    "print(X_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['word.lower=furthermore', 'word[-3:]=ore', 'word[0:]=Furthermore', 'word[-1:]=e', 'word[-2:]=re', 'word.isupper=False', 'word.isdigit=False', 'word.startsWithCapital=True', 'word.pos=ADV', 'BEG'], ['word.lower=,', 'word[-3:]=,', 'word[0:]=,', 'word[-1:]=,', 'word[-2:]=,', 'word.isupper=False', 'word.isdigit=False', 'word.startsWithCapital=False', 'word.pos=PUNCT', 'prev_word.lower=furthermore', 'prev_word.isupper=False', 'prev_word.isdigit=False', 'prev_word.startsWithCapital=True', 'prev_word.pos=ADV'], ['word.lower=when', 'word[-3:]=hen', 'word[0:]=when', 'word[-1:]=n', 'word[-2:]=en', 'word.isupper=False', 'word.isdigit=False', 'word.startsWithCapital=False', 'word.pos=ADV', 'prev_word.lower=,', 'prev_word.isupper=False', 'prev_word.isdigit=False', 'prev_word.startsWithCapital=False', 'prev_word.pos=PUNCT'], ['word.lower=all', 'word[-3:]=all', 'word[0:]=all', 'word[-1:]=l', 'word[-2:]=ll', 'word.isupper=False', 'word.isdigit=False', 'word.startsWithCapital=False', 'word.pos=DET', 'prev_word.lower=when', 'prev_word.isupper=False', 'prev_word.isdigit=False', 'prev_word.startsWithCapital=False', 'prev_word.pos=ADV'], ['word.lower=deliveries', 'word[-3:]=ies', 'word[0:]=deliveries', 'word[-1:]=s', 'word[-2:]=es', 'word.isupper=False', 'word.isdigit=False', 'word.startsWithCapital=False', 'word.pos=NOUN', 'prev_word.lower=all', 'prev_word.isupper=False', 'prev_word.isdigit=False', 'prev_word.startsWithCapital=False', 'prev_word.pos=DET'], ['word.lower=were', 'word[-3:]=ere', 'word[0:]=were', 'word[-1:]=e', 'word[-2:]=re', 'word.isupper=False', 'word.isdigit=False', 'word.startsWithCapital=False', 'word.pos=AUX', 'prev_word.lower=deliveries', 'prev_word.isupper=False', 'prev_word.isdigit=False', 'prev_word.startsWithCapital=False', 'prev_word.pos=NOUN'], ['word.lower=analyzed', 'word[-3:]=zed', 'word[0:]=analyzed', 'word[-1:]=d', 'word[-2:]=ed', 'word.isupper=False', 'word.isdigit=False', 'word.startsWithCapital=False', 'word.pos=VERB', 'prev_word.lower=were', 'prev_word.isupper=False', 'prev_word.isdigit=False', 'prev_word.startsWithCapital=False', 'prev_word.pos=AUX'], ['word.lower=,', 'word[-3:]=,', 'word[0:]=,', 'word[-1:]=,', 'word[-2:]=,', 'word.isupper=False', 'word.isdigit=False', 'word.startsWithCapital=False', 'word.pos=PUNCT', 'prev_word.lower=analyzed', 'prev_word.isupper=False', 'prev_word.isdigit=False', 'prev_word.startsWithCapital=False', 'prev_word.pos=VERB'], ['word.lower=regardless', 'word[-3:]=ess', 'word[0:]=regardless', 'word[-1:]=s', 'word[-2:]=ss', 'word.isupper=False', 'word.isdigit=False', 'word.startsWithCapital=False', 'word.pos=ADV', 'prev_word.lower=,', 'prev_word.isupper=False', 'prev_word.isdigit=False', 'prev_word.startsWithCapital=False', 'prev_word.pos=PUNCT'], ['word.lower=of', 'word[-3:]=of', 'word[0:]=of', 'word[-1:]=f', 'word[-2:]=of', 'word.isupper=False', 'word.isdigit=False', 'word.startsWithCapital=False', 'word.pos=ADP', 'prev_word.lower=regardless', 'prev_word.isupper=False', 'prev_word.isdigit=False', 'prev_word.startsWithCapital=False', 'prev_word.pos=ADV'], ['word.lower=risk', 'word[-3:]=isk', 'word[0:]=risk', 'word[-1:]=k', 'word[-2:]=sk', 'word.isupper=False', 'word.isdigit=False', 'word.startsWithCapital=False', 'word.pos=NOUN', 'prev_word.lower=of', 'prev_word.isupper=False', 'prev_word.isdigit=False', 'prev_word.startsWithCapital=False', 'prev_word.pos=ADP'], ['word.lower=status', 'word[-3:]=tus', 'word[0:]=status', 'word[-1:]=s', 'word[-2:]=us', 'word.isupper=False', 'word.isdigit=False', 'word.startsWithCapital=False', 'word.pos=NOUN', 'prev_word.lower=risk', 'prev_word.isupper=False', 'prev_word.isdigit=False', 'prev_word.startsWithCapital=False', 'prev_word.pos=NOUN'], ['word.lower=but', 'word[-3:]=but', 'word[0:]=but', 'word[-1:]=t', 'word[-2:]=ut', 'word.isupper=False', 'word.isdigit=False', 'word.startsWithCapital=False', 'word.pos=CCONJ', 'prev_word.lower=status', 'prev_word.isupper=False', 'prev_word.isdigit=False', 'prev_word.startsWithCapital=False', 'prev_word.pos=NOUN'], ['word.lower=limited', 'word[-3:]=ted', 'word[0:]=limited', 'word[-1:]=d', 'word[-2:]=ed', 'word.isupper=False', 'word.isdigit=False', 'word.startsWithCapital=False', 'word.pos=VERB', 'prev_word.lower=but', 'prev_word.isupper=False', 'prev_word.isdigit=False', 'prev_word.startsWithCapital=False', 'prev_word.pos=CCONJ'], ['word.lower=to', 'word[-3:]=to', 'word[0:]=to', 'word[-1:]=o', 'word[-2:]=to', 'word.isupper=False', 'word.isdigit=False', 'word.startsWithCapital=False', 'word.pos=ADP', 'prev_word.lower=limited', 'prev_word.isupper=False', 'prev_word.isdigit=False', 'prev_word.startsWithCapital=False', 'prev_word.pos=VERB'], ['word.lower=gestational', 'word[-3:]=nal', 'word[0:]=gestational', 'word[-1:]=l', 'word[-2:]=al', 'word.isupper=False', 'word.isdigit=False', 'word.startsWithCapital=False', 'word.pos=ADJ', 'prev_word.lower=to', 'prev_word.isupper=False', 'prev_word.isdigit=False', 'prev_word.startsWithCapital=False', 'prev_word.pos=ADP'], ['word.lower=age', 'word[-3:]=age', 'word[0:]=age', 'word[-1:]=e', 'word[-2:]=ge', 'word.isupper=False', 'word.isdigit=False', 'word.startsWithCapital=False', 'word.pos=NOUN', 'prev_word.lower=gestational', 'prev_word.isupper=False', 'prev_word.isdigit=False', 'prev_word.startsWithCapital=False', 'prev_word.pos=ADJ'], ['word.lower=>', 'word[-3:]=>', 'word[0:]=>', 'word[-1:]=>', 'word[-2:]=>', 'word.isupper=False', 'word.isdigit=False', 'word.startsWithCapital=False', 'word.pos=PUNCT', 'prev_word.lower=age', 'prev_word.isupper=False', 'prev_word.isdigit=False', 'prev_word.startsWithCapital=False', 'prev_word.pos=NOUN'], ['word.lower=or', 'word[-3:]=or', 'word[0:]=or', 'word[-1:]=r', 'word[-2:]=or', 'word.isupper=False', 'word.isdigit=False', 'word.startsWithCapital=False', 'word.pos=CCONJ', 'prev_word.lower=>', 'prev_word.isupper=False', 'prev_word.isdigit=False', 'prev_word.startsWithCapital=False', 'prev_word.pos=PUNCT'], ['word.lower==', 'word[-3:]==', 'word[0:]==', 'word[-1:]==', 'word[-2:]==', 'word.isupper=False', 'word.isdigit=False', 'word.startsWithCapital=False', 'word.pos=SYM', 'prev_word.lower=or', 'prev_word.isupper=False', 'prev_word.isdigit=False', 'prev_word.startsWithCapital=False', 'prev_word.pos=CCONJ'], ['word.lower=36', 'word[-3:]=36', 'word[0:]=36', 'word[-1:]=6', 'word[-2:]=36', 'word.isupper=False', 'word.isdigit=True', 'word.startsWithCapital=False', 'word.pos=NUM', 'prev_word.lower==', 'prev_word.isupper=False', 'prev_word.isdigit=False', 'prev_word.startsWithCapital=False', 'prev_word.pos=SYM'], ['word.lower=weeks', 'word[-3:]=eks', 'word[0:]=weeks', 'word[-1:]=s', 'word[-2:]=ks', 'word.isupper=False', 'word.isdigit=False', 'word.startsWithCapital=False', 'word.pos=NOUN', 'prev_word.lower=36', 'prev_word.isupper=False', 'prev_word.isdigit=True', 'prev_word.startsWithCapital=False', 'prev_word.pos=NUM'], ['word.lower=,', 'word[-3:]=,', 'word[0:]=,', 'word[-1:]=,', 'word[-2:]=,', 'word.isupper=False', 'word.isdigit=False', 'word.startsWithCapital=False', 'word.pos=PUNCT', 'prev_word.lower=weeks', 'prev_word.isupper=False', 'prev_word.isdigit=False', 'prev_word.startsWithCapital=False', 'prev_word.pos=NOUN'], ['word.lower=the', 'word[-3:]=the', 'word[0:]=the', 'word[-1:]=e', 'word[-2:]=he', 'word.isupper=False', 'word.isdigit=False', 'word.startsWithCapital=False', 'word.pos=DET', 'prev_word.lower=,', 'prev_word.isupper=False', 'prev_word.isdigit=False', 'prev_word.startsWithCapital=False', 'prev_word.pos=PUNCT'], ['word.lower=rates', 'word[-3:]=tes', 'word[0:]=rates', 'word[-1:]=s', 'word[-2:]=es', 'word.isupper=False', 'word.isdigit=False', 'word.startsWithCapital=False', 'word.pos=NOUN', 'prev_word.lower=the', 'prev_word.isupper=False', 'prev_word.isdigit=False', 'prev_word.startsWithCapital=False', 'prev_word.pos=DET'], ['word.lower=did', 'word[-3:]=did', 'word[0:]=did', 'word[-1:]=d', 'word[-2:]=id', 'word.isupper=False', 'word.isdigit=False', 'word.startsWithCapital=False', 'word.pos=AUX', 'prev_word.lower=rates', 'prev_word.isupper=False', 'prev_word.isdigit=False', 'prev_word.startsWithCapital=False', 'prev_word.pos=NOUN'], ['word.lower=not', 'word[-3:]=not', 'word[0:]=not', 'word[-1:]=t', 'word[-2:]=ot', 'word.isupper=False', 'word.isdigit=False', 'word.startsWithCapital=False', 'word.pos=PART', 'prev_word.lower=did', 'prev_word.isupper=False', 'prev_word.isdigit=False', 'prev_word.startsWithCapital=False', 'prev_word.pos=AUX'], ['word.lower=change', 'word[-3:]=nge', 'word[0:]=change', 'word[-1:]=e', 'word[-2:]=ge', 'word.isupper=False', 'word.isdigit=False', 'word.startsWithCapital=False', 'word.pos=VERB', 'prev_word.lower=not', 'prev_word.isupper=False', 'prev_word.isdigit=False', 'prev_word.startsWithCapital=False', 'prev_word.pos=PART'], ['word.lower=(', 'word[-3:]=(', 'word[0:]=(', 'word[-1:]=(', 'word[-2:]=(', 'word.isupper=False', 'word.isdigit=False', 'word.startsWithCapital=False', 'word.pos=PUNCT', 'prev_word.lower=change', 'prev_word.isupper=False', 'prev_word.isdigit=False', 'prev_word.startsWithCapital=False', 'prev_word.pos=VERB'], ['word.lower=12.6', 'word[-3:]=2.6', 'word[0:]=12.6', 'word[-1:]=6', 'word[-2:]=.6', 'word.isupper=False', 'word.isdigit=False', 'word.startsWithCapital=False', 'word.pos=NUM', 'prev_word.lower=(', 'prev_word.isupper=False', 'prev_word.isdigit=False', 'prev_word.startsWithCapital=False', 'prev_word.pos=PUNCT'], ['word.lower=%', 'word[-3:]=%', 'word[0:]=%', 'word[-1:]=%', 'word[-2:]=%', 'word.isupper=False', 'word.isdigit=False', 'word.startsWithCapital=False', 'word.pos=NOUN', 'prev_word.lower=12.6', 'prev_word.isupper=False', 'prev_word.isdigit=False', 'prev_word.startsWithCapital=False', 'prev_word.pos=NUM'], ['word.lower=,', 'word[-3:]=,', 'word[0:]=,', 'word[-1:]=,', 'word[-2:]=,', 'word.isupper=False', 'word.isdigit=False', 'word.startsWithCapital=False', 'word.pos=PUNCT', 'prev_word.lower=%', 'prev_word.isupper=False', 'prev_word.isdigit=False', 'prev_word.startsWithCapital=False', 'prev_word.pos=NOUN'], ['word.lower=280', 'word[-3:]=280', 'word[0:]=280', 'word[-1:]=0', 'word[-2:]=80', 'word.isupper=False', 'word.isdigit=True', 'word.startsWithCapital=False', 'word.pos=NUM', 'prev_word.lower=,', 'prev_word.isupper=False', 'prev_word.isdigit=False', 'prev_word.startsWithCapital=False', 'prev_word.pos=PUNCT'], ['word.lower=of', 'word[-3:]=of', 'word[0:]=of', 'word[-1:]=f', 'word[-2:]=of', 'word.isupper=False', 'word.isdigit=False', 'word.startsWithCapital=False', 'word.pos=ADP', 'prev_word.lower=280', 'prev_word.isupper=False', 'prev_word.isdigit=True', 'prev_word.startsWithCapital=False', 'prev_word.pos=NUM'], ['word.lower=2214', 'word[-3:]=214', 'word[0:]=2214', 'word[-1:]=4', 'word[-2:]=14', 'word.isupper=False', 'word.isdigit=True', 'word.startsWithCapital=False', 'word.pos=NUM', 'prev_word.lower=of', 'prev_word.isupper=False', 'prev_word.isdigit=False', 'prev_word.startsWithCapital=False', 'prev_word.pos=ADP'], ['word.lower=;', 'word[-3:]=;', 'word[0:]=;', 'word[-1:]=;', 'word[-2:]=;', 'word.isupper=False', 'word.isdigit=False', 'word.startsWithCapital=False', 'word.pos=PUNCT', 'prev_word.lower=2214', 'prev_word.isupper=False', 'prev_word.isdigit=True', 'prev_word.startsWithCapital=False', 'prev_word.pos=NUM'], ['word.lower=primary', 'word[-3:]=ary', 'word[0:]=primary', 'word[-1:]=y', 'word[-2:]=ry', 'word.isupper=False', 'word.isdigit=False', 'word.startsWithCapital=False', 'word.pos=ADJ', 'prev_word.lower=;', 'prev_word.isupper=False', 'prev_word.isdigit=False', 'prev_word.startsWithCapital=False', 'prev_word.pos=PUNCT'], ['word.lower=9.2', 'word[-3:]=9.2', 'word[0:]=9.2', 'word[-1:]=2', 'word[-2:]=.2', 'word.isupper=False', 'word.isdigit=False', 'word.startsWithCapital=False', 'word.pos=NUM', 'prev_word.lower=primary', 'prev_word.isupper=False', 'prev_word.isdigit=False', 'prev_word.startsWithCapital=False', 'prev_word.pos=ADJ'], ['word.lower=%', 'word[-3:]=%', 'word[0:]=%', 'word[-1:]=%', 'word[-2:]=%', 'word.isupper=False', 'word.isdigit=False', 'word.startsWithCapital=False', 'word.pos=NOUN', 'prev_word.lower=9.2', 'prev_word.isupper=False', 'prev_word.isdigit=False', 'prev_word.startsWithCapital=False', 'prev_word.pos=NUM'], ['word.lower=,', 'word[-3:]=,', 'word[0:]=,', 'word[-1:]=,', 'word[-2:]=,', 'word.isupper=False', 'word.isdigit=False', 'word.startsWithCapital=False', 'word.pos=PUNCT', 'prev_word.lower=%', 'prev_word.isupper=False', 'prev_word.isdigit=False', 'prev_word.startsWithCapital=False', 'prev_word.pos=NOUN'], ['word.lower=183', 'word[-3:]=183', 'word[0:]=183', 'word[-1:]=3', 'word[-2:]=83', 'word.isupper=False', 'word.isdigit=True', 'word.startsWithCapital=False', 'word.pos=NUM', 'prev_word.lower=,', 'prev_word.isupper=False', 'prev_word.isdigit=False', 'prev_word.startsWithCapital=False', 'prev_word.pos=PUNCT'], ['word.lower=of', 'word[-3:]=of', 'word[0:]=of', 'word[-1:]=f', 'word[-2:]=of', 'word.isupper=False', 'word.isdigit=False', 'word.startsWithCapital=False', 'word.pos=ADP', 'prev_word.lower=183', 'prev_word.isupper=False', 'prev_word.isdigit=True', 'prev_word.startsWithCapital=False', 'prev_word.pos=NUM'], ['word.lower=1994', 'word[-3:]=994', 'word[0:]=1994', 'word[-1:]=4', 'word[-2:]=94', 'word.isupper=False', 'word.isdigit=True', 'word.startsWithCapital=False', 'word.pos=NUM', 'prev_word.lower=of', 'prev_word.isupper=False', 'prev_word.isdigit=False', 'prev_word.startsWithCapital=False', 'prev_word.pos=ADP'], ['word.lower=)', 'word[-3:]=)', 'word[0:]=)', 'word[-1:]=)', 'word[-2:]=)', 'word.isupper=False', 'word.isdigit=False', 'word.startsWithCapital=False', 'word.pos=PUNCT', 'prev_word.lower=1994', 'prev_word.isupper=False', 'prev_word.isdigit=True', 'prev_word.startsWithCapital=False', 'prev_word.pos=NUM', 'END']]\n"
     ]
    }
   ],
   "source": [
    "print(X_test[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the labels as the target variable for test and the train dataset\n",
    "Y_train = [getLabelsInListForOneSentence(labels) for labels in train_labels]\n",
    "Y_test = [getLabelsInListForOneSentence(labels) for labels in test_labels]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n"
     ]
    }
   ],
   "source": [
    "print(Y_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n"
     ]
    }
   ],
   "source": [
    "print(Y_test[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building the model\n",
    "You need to build the CRF model for a custom NER application using the features and the target variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the model\n",
    "crf_model = sklearn_crfsuite.CRF(max_iterations=100)\n",
    "try:\n",
    "    crf_model.fit(X_train, Y_train)\n",
    "except AttributeError:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation\n",
    "- Predict the labels of each of the tokens in each sentence of the test dataset that has been preprocessed earlier.\n",
    "- Calculate the f1 score using the actual and the predicted labels of the test dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict the labels of each of the tokens in each sentence of the test dataset that has been preprocessed earlier.\n",
    "Y_pred = crf_model.predict(X_test)\n",
    "pred_label=[]\n",
    "for i in Y_pred:\n",
    "    pred_label.extend(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9104780783739593"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate the f1 score using the actual labels and the predicted labels of the test dataset.\n",
    "metrics.flat_f1_score(Y_test, Y_pred, average='weighted')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- We got 91% as f1_score by using the actual labels and the predicted labels of the test dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Identifying the diseases and treatment using a custom NER\n",
    "Create the code or logic to get all the predicted treatments (T) labels corresponding to each disease (D) label in the test dataset. You can refer to the following image to get an idea on how to create a dictionary where diseases are working as keys and treatments are working as values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write a logic to get the disease and treatments in dictionary format where disease is key and the treatment should be the values\n",
    "diseases_and_treatments =  {} # dictionary with disease as key an list of treatments as value\n",
    "\n",
    "for i in range(len(Y_pred)): # For each predicted sequence\n",
    "  labels = Y_pred[i]\n",
    "\n",
    "  disease = \"\";\n",
    "  treatment = \"\";\n",
    "  \n",
    "  for j in range(len(labels)): # for each individual label in the sequence\n",
    "    if labels[j] == 'O': # ignore if label is O -- other\n",
    "      continue\n",
    "\n",
    "    if(labels[j] == 'D'): # Label D indicates disease, so add the corresponding word from test sentence to the disease name string\n",
    "      disease += test_sentences[i].split()[j] + \" \"\n",
    "      continue\n",
    "\n",
    "    if(labels[j] == 'T'): # Label T indicates treatment, so add the corresponding word from test sentence to the treatment name string\n",
    "      treatment += test_sentences[i].split()[j] + \" \"\n",
    "\n",
    "  disease = disease.strip() # to remove extraneous spaces\n",
    "  treatment = treatment.strip()\n",
    "\n",
    "  # add the identified disease and treatment to the dictionary\n",
    "  # if it is a new disease, directly add the value\n",
    "  # if the disease has been seen previously, get the treatment list\n",
    "  # and add current treatment to the list.\n",
    "  if disease != \"\" and treatment != \"\":\n",
    "    if disease not in diseases_and_treatments.keys():\n",
    "      diseases_and_treatments[disease] = [treatment]\n",
    "    else:\n",
    "      treatment_list = diseases_and_treatments.get(disease)\n",
    "      treatment_list.append(treatment)\n",
    "      diseases_and_treatments[disease] = treatment_list "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'hereditary retinoblastoma': ['radiotherapy'],\n",
       " 'unstable angina or non-Q-wave myocardial infarction': ['roxithromycin'],\n",
       " 'coronary-artery disease': ['Antichlamydial antibiotics'],\n",
       " 'primary pulmonary hypertension': ['fenfluramines'],\n",
       " 'essential hypertension': ['moxonidine'],\n",
       " 'foot infection': ['G-CSF treatment'],\n",
       " 'hemorrhagic stroke': ['double-bolus alteplase'],\n",
       " \"early Parkinson 's disease\": ['Ropinirole monotherapy'],\n",
       " 'abdominal tuberculosis': ['steroids'],\n",
       " 'treating stress urinary incontinence': ['surgical procedures'],\n",
       " 'female stress urinary incontinence': ['surgical treatment'],\n",
       " 'stress urinary incontinence': ['therapy'],\n",
       " 'preeclampsia ( proteinuric hypertension': ['intrauterine insemination with donor sperm versus intrauterine insemination'],\n",
       " 'cancer': ['organ transplantation and chemotherapy',\n",
       "  'oral drugs chemotherapy',\n",
       "  'Matrix metalloproteinase inhibitors'],\n",
       " 'major pulmonary embolism': ['Thrombolytic treatment',\n",
       "  'Association between thrombolytic treatment'],\n",
       " 'malignant pleural mesothelioma': ['thoracotomy , radiotherapy , and chemotherapy'],\n",
       " 'tumor pulmonary symptoms attributable': ['chemotherapy'],\n",
       " 'non-obstructive azoospermia': ['testicular fine needle aspiration ( TEFNA ) open biopsy and testicular sperm extraction ( TESE )'],\n",
       " 'colorectal cancer': ['Elective surgery'],\n",
       " 'gastrointestinal tumours': ['Elective surgery'],\n",
       " \"Parkinson 's disease\": ['Microelectrode-guided posteroventral pallidotomy'],\n",
       " 'soft tissue sarcomas': ['Radiotherapy'],\n",
       " \"Eisenmenger 's syndrome\": ['laparoscopic cholecystectomy'],\n",
       " 'advanced esophageal cancer': ['adjuvant chemoradiotherapy with CDDP'],\n",
       " 'breast cancer': ['Hormone replacement therapy',\n",
       "  'undergone subcutaneous mastectomy and immediate reconstruction'],\n",
       " 'leukemia': ['Trisomy'],\n",
       " 'some malignant tumors such as non-small cell lung cancer': ['surgery'],\n",
       " 'inoperable advanced malignancies such as colorectal cancer': ['combination with leucovorin or cisplatin'],\n",
       " 'abdominal pain': ['thoracic paravertebral block ( tpvb )'],\n",
       " 'inflammatory skin diseases': ['topical corticosteroids'],\n",
       " 'unresectable stage iii nsclc': ['sequential chemotherapy'],\n",
       " 'nsclc nsclc ( stage iiib ) sclc , limited disease': ['got surgical treatment'],\n",
       " 'nsclc': ['platinum-based chemotherapy', 'chemotherapy'],\n",
       " 'locally advanced non-small-cell lung cancer ( la-nsclc )': ['chemotherapy and radiotherapy )'],\n",
       " 'radiation-induced myelopathy': ['heparin and enoxaparin'],\n",
       " 'limited stage small cell lung cancer': ['vip combination chemotherapy and early concurrent thoracic irradiation'],\n",
       " 'malignant pleural effusions from nsclc': ['systemic chemotherapy'],\n",
       " 'small-cell lung cancer': ['chemotherapy', 'combination chemotherapy'],\n",
       " 'intraluminal early-stage cancer': ['photodynamic therapy , nd-yag laser and electrocautery'],\n",
       " 'supraclavicular node metastases in nsclc': ['chemoradiotherapy'],\n",
       " 'non-small-cell-lung-cancer ( nsclc )': ['cisplatin and radiotherapy'],\n",
       " 'lung carcinoma': ['videothoracoscopic lobectomy or partial resection open thoracotomy',\n",
       "  'curative therapy'],\n",
       " 'single non-sclc melanoma ovarian carcinoma brain metastasis': ['surgical resection'],\n",
       " 'colorectal metastases': ['therapeutic vats metastasectomy'],\n",
       " 'advanced nsclc': ['assessing combination chemotherapy of cisplatin , ifosfamide and irinotecan with rhg-csf support'],\n",
       " 'metastatic colorectal cancer': ['intravenous oxaliplatin'],\n",
       " \"non-hodgkin 's lymphoma , breast cancer mesothelioma and non-small cell lung cancer\": ['oxaliplatin'],\n",
       " 'other cancers platinum-pretreated ovarian cancer': ['oxaliplatin'],\n",
       " 'primary tumor bronchogenic carcinoma': ['resection'],\n",
       " 'non-small cell lung cancer advanced hormone refractory prostate cancer': ['paclitaxel and carboplatin'],\n",
       " 'primary lung cancer adenocarcinoma squamous cell carcinoma': ['resection'],\n",
       " 'stage iii nsclc': ['chemotherapy administered before surgery'],\n",
       " 'small cell lung cancer': ['prophylactic cranial irradiation'],\n",
       " 'primary cancer': ['adjuvant radiation therapy'],\n",
       " 'advanced non -- small-cell lung cancer': ['paclitaxel plus carboplatin ( pc ) vinorelbine plus cisplatin ( vc )'],\n",
       " 'two-year survivors among sclc limited disease extensive disease': ['platinum dose ( cisplatin plus carboplatin ) in combination chemotherapy combination therapy with carboplatin'],\n",
       " 'untreated small cell lung cancer ( sclc ) untreated sclc': ['chemotherapy'],\n",
       " 'head and neck cancer': ['irradiation therapy intravenous amifostine'],\n",
       " 'psoriasis': ['topical application of active vitamin D3 analogue , 1 alpha'],\n",
       " 'disseminated malignant melanoma': ['leukocyte A recombinant interferon ( rIFN-alpha A , Roferon-A , Hoffmann La Roche )'],\n",
       " 'advanced stage ( TNM IIB-IVB ) mycosis fungoides': ['a combination chemotherapy program consisting of bleomycin and methotrexate weekly , doxorubicin every'],\n",
       " 'ventricular tachycardia': ['Guiding surgical therapy'],\n",
       " 'syringomyelia spinal adhesive arachnoiditis': ['Surgical management'],\n",
       " 'bronchiectasis': ['antibiotics and surgery', 'Current surgical therapy'],\n",
       " 'biliary dyskinesia': ['Cholecystectomy'],\n",
       " 'symptoms the common cold': ['pseudoephedrine plus acetaminophen'],\n",
       " 'acute nasopharyngitis': ['antibiotic treatment'],\n",
       " 'symptoms of a common cold': ['Macrolide antibiotics'],\n",
       " 'infection rhinovirus': ['clarithromycin'],\n",
       " 'infection': ['a combination of omeprazole , amoxicillin , and clarithromycin'],\n",
       " 'persistent asthma': ['Contemporary asthma management guidelines list inhaled corticosteroids'],\n",
       " 'asthma': ['Fluticasone propionate several inhaled corticosteroids'],\n",
       " 'chronic hepatitis C': ['Combination therapy with interferon-alpha ( IFN alpha ) plus Ribavirin'],\n",
       " 'hepatitis C viremia': ['combination therapy'],\n",
       " 'duodenogastric reflux': ['cholecystectomy'],\n",
       " 'severe hypoxemia': ['glucocorticoid pulse therapy'],\n",
       " 'bacterial meningitis': ['New vaccines'],\n",
       " 'primary sclerosing cholangitis': ['oral budesonide'],\n",
       " 'acute myocardial infarction': ['Thrombolytic therapy',\n",
       "  'thrombolytic treatment'],\n",
       " 'preexisting cancers cancer': ['Immunotherapy'],\n",
       " 'peritoneal tumors': ['Subcutaneous injection of irradiated LLC-IL2'],\n",
       " 'acute occlusion of the middle cerebral artery': ['thrombolytic therapy'],\n",
       " 'autoimmune diseases': ['High-dose intravenous immunoglobulin ( hdIVIg )'],\n",
       " 'phaeochromocytoma': ['Adrenalectomy'],\n",
       " 'malignant melanoma': ['As single agent therapy interferon alfa-2a'],\n",
       " 'advanced renal cell carcinoma': ['various interferon alpha preparations interferon alfa-N1 , interferon alfa-2a , and interferon alfa-2b'],\n",
       " 'hairy cell leukemia infection': ['antileukemic therapy'],\n",
       " \"low-grade non-Hodgkin 's lymphoma\": ['Recombinant and natural forms of interferon alpha'],\n",
       " 'esophageal achalasia': ['botulinum toxin injection , pneumatic dilation , and laparoscopic myotomy'],\n",
       " 'proximal hypospadias': ['Tubularized incised plate hypospadias repair'],\n",
       " 'prostate cancer': ['radical prostatectomy and iodine 125 interstitial radiotherapy'],\n",
       " 'tumors': ['Immunotherapy'],\n",
       " 'mitomycin-resistant bladder cancer': ['photodynamic therapy in combination with mitomycin C'],\n",
       " 'B16 melanoma': ['adenosine triphosphate and treatment with buthionine sulfoximine'],\n",
       " 'primary uveal melanoma': ['transpupillary thermotherapy'],\n",
       " 'advanced rectal cancer': ['Nerve-sparing surgery'],\n",
       " 'spontaneous pneumothorax': ['Thoracoscopic surgery'],\n",
       " 'acute cerebral ischemia': ['Antiplatelet therapy'],\n",
       " 'renal cell carcinoma': ['Interferon treatment'],\n",
       " 'myocardial angiogenesis': ['Gene therapy'],\n",
       " 'autoimmune hemolytic anemia': ['heparin'],\n",
       " 'multiple sclerosis': ['Interferon beta treatment',\n",
       "  'Intravenous immunoglobulin treatment'],\n",
       " 'acoustic neuroma': ['Stereotactic radiosurgery'],\n",
       " 'cerebral palsy': ['Hyperbaric oxygen therapy'],\n",
       " 'postvitrectomy diabetic vitreous hemorrhage': ['Peripheral retinal cryotherapy'],\n",
       " 'hepatitis B': ['vaccine'],\n",
       " 'temporomandibular joint arthropathy': ['arthroscopic treatment'],\n",
       " 'severe secondary peritonitis': ['Surgical management'],\n",
       " 'hepatic metastases from colorectal cancer': ['Hepatic arterial infusion of chemotherapy after resection'],\n",
       " 'Poliomyelitis': ['oral poliovirus vaccines'],\n",
       " 'chronic renal failure': ['Epoetin'],\n",
       " 'epithelial ovarian cancer': ['High-dose chemotherapy']}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diseases_and_treatments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict the treatment for the disease named 'hereditary retinoblastoma'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Disease:  hereditary retinoblastoma\n",
      "Treatment: ['radiotherapy']\n"
     ]
    }
   ],
   "source": [
    "diseases_identified = list(diseases_and_treatments.keys())\n",
    "index = 0 \n",
    "\n",
    "print(\"Disease: \",diseases_identified[index])\n",
    "print(\"Treatment:\", diseases_and_treatments.get(diseases_identified[index]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Hereditary Retinoblastoma can be treated by Radiotherapy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
